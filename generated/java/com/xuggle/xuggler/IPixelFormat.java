/* ----------------------------------------------------------------------------
 * This file was automatically generated by SWIG (http://www.swig.org).
 * Version 4.0.2
 *
 * Do not make changes to this file unless you know what you are doing--modify
 * the SWIG interface file instead.
 * ----------------------------------------------------------------------------- */

package com.xuggle.xuggler;
import com.xuggle.ferry.*;
/**
 * Information about how video data is formatted in an {IVideoPicture} object.<br>
 * <br>
 * This specifies the color space and how many bits pixel data takes.  It also<br>
 * includes some utility methods for dealing with {Type#YUV420P} data; the<br>
 * most common type of encoding used in video files I've run across.
 */
public class IPixelFormat extends RefCounted {
  private transient long swigCPtr;

  protected IPixelFormat(long cPtr, boolean cMemoryOwn) {
    super(XugglerJNI.IPixelFormat_SWIGUpcast(cPtr), cMemoryOwn);
    swigCPtr = cPtr;
  }

  protected static long getCPtr(IPixelFormat obj) {
    return (obj == null) ? 0 : obj.swigCPtr;
  }

  public synchronized void delete() {
    if (swigCPtr != 0) {
      if (swigCMemOwn) {
        swigCMemOwn = false;
        throw new UnsupportedOperationException("C++ destructor does not have public access");
      }
      swigCPtr = 0;
    }
    super.delete();
  }



  /**
   * Returns the byte for the coordinates at x and y for the color component c.<br>
   * <br>
   * @param frame The frame to get the byte from<br>
   * @param x X coordinate in pixels, where 0 is the left hand edge of the image. <br>
   * @param y Y coordinate in pixels, where 0 is the top edge of the image. <br>
   * @param c YUVColor component<br>
   * <br>
   * @throws std::exception frame is null, the coordinates are invalid, or if the pixel format is not YUV420P<br>
   * <br>
   * @return the pixel byte for that x, y, c combination 
   */
  public static short getYUV420PPixel(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c) {
    return XugglerJNI.IPixelFormat_getYUV420PPixel(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue());
  }

  /**
   * Sets the value of the color component c at the coordinates x and y in the given frame.<br>
   * <br>
   * @param frame The frame to set the byte in<br>
   * @param x X coordinate in pixels, where 0 is the left hand edge of the image. <br>
   * @param y Y coordinate in pixels, where 0 is the top edge of the image. <br>
   * @param c YUVColor component to set<br>
   * @param value The new value of that pixel color component<br>
   * <br>
   * @throws std::exception frame is null, the coordinates are invalid, or if the pixel format is not YUV420P 
   */
  public static void setYUV420PPixel(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c, short value) {
    XugglerJNI.IPixelFormat_setYUV420PPixel(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue(), value);
  }

  /**
   * For a given x and y in a frame, and a given color components, this method<br>
   * tells you how far into the actual data you'd have to go to find the byte that<br>
   * represents that color/coordinate combination.<br>
   * <br>
   * @param frame The frame to get the byte from<br>
   * @param x X coordinate in pixels, where 0 is the left hand edge of the image. <br>
   * @param y Y coordinate in pixels, where 0 is the top edge of the image. <br>
   * @param c YUVColor component<br>
   * <br>
   * @throws std::exception frame is null, the coordinates are invalid, or if the pixel format is not YUV420P<br>
   * <br>
   * @return the offset in bytes, starting from the start of the frame data, where<br>
   *   the data for this pixel resides.
   */
  public static int getYUV420PPixelOffset(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c) {
    return XugglerJNI.IPixelFormat_getYUV420PPixelOffset(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue());
  }

  /**
   * Pixel format. Notes:<br>
   * <br>
   * RGB32 is handled in an endian-specific manner. A RGBA<br>
   * color is put together as:<br>
   *  (A &lt;< 24) | (R &lt;< 16) | (G &lt;< 8) | B<br>
   * This is stored as BGRA on little endian CPU architectures and ARGB on<br>
   * big endian CPUs.<br>
   * <br>
   * When the pixel format is palettized RGB (PAL8), the palettized<br>
   * image data is stored in AVFrame.data[0]. The palette is transported in<br>
   * AVFrame.data[1] and, is 1024 bytes long (256 4-byte entries) and is<br>
   * formatted the same as in RGB32 described above (i.e., it is<br>
   * also endian-specific). Note also that the individual RGB palette<br>
   * components stored in AVFrame.data[1] should be in the range 0..255.<br>
   * This is important as many custom PAL8 video codecs that were designed<br>
   * to run on the IBM VGA graphics adapter use 6-bit palette components.
   */
  public enum Type {
    NONE(XugglerJNI.IPixelFormat_NONE_get()),
    /**
     *  planar YUV 4:2:0, 12bpp, (1 Cr &amp; Cb sample per 2x2 Y samples)
     */
    YUV420P,
    /**
     *  packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr
     */
    YUYV422,
    /**
     *  packed RGB 8:8:8, 24bpp, RGBRGB...
     */
    RGB24,
    /**
     *  packed RGB 8:8:8, 24bpp, BGRBGR...
     */
    BGR24,
    /**
     *  planar YUV 4:2:2, 16bpp, (1 Cr &amp; Cb sample per 2x1 Y samples)
     */
    YUV422P,
    /**
     *  planar YUV 4:4:4, 24bpp, (1 Cr &amp; Cb sample per 1x1 Y samples)
     */
    YUV444P,
    /**
     *  planar YUV 4:1:0,  9bpp, (1 Cr &amp; Cb sample per 4x4 Y samples)
     */
    YUV410P,
    /**
     *  planar YUV 4:1:1, 12bpp, (1 Cr &amp; Cb sample per 4x1 Y samples)
     */
    YUV411P,
    /**
     *         Y        ,  8bpp
     */
    GRAY8,
    /**
     *         Y        ,  1bpp, 0 is white, 1 is black, in each byte pixels are ordered from the msb to the lsb
     */
    MONOWHITE,
    /**
     *         Y        ,  1bpp, 0 is black, 1 is white, in each byte pixels are ordered from the msb to the lsb
     */
    MONOBLACK,
    /**
     *  8 bit with RGB32 palette
     */
    PAL8,
    /**
     *  planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated in favor of YUV420P and setting color_range
     */
    YUVJ420P,
    /**
     *  planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated in favor of YUV422P and setting color_range
     */
    YUVJ422P,
    /**
     *  planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated in favor of YUV444P and setting color_range
     */
    YUVJ444P,
    /**
     *  XVideo Motion Acceleration via common packet passing
     */
    XVMC_MPEG2_MC,
    XVMC_MPEG2_IDCT,
    /**
     *  packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1
     */
    UYVY422,
    /**
     *  packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3
     */
    UYYVYY411,
    /**
     *  packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb)
     */
    BGR8,
    /**
     *  packed RGB 1:2:1 bitstream,  4bpp, (msb)1B 2G 1R(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits
     */
    BGR4,
    /**
     *  packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb)
     */
    BGR4_BYTE,
    /**
     *  packed RGB 3:3:2,  8bpp, (msb)2R 3G 3B(lsb)
     */
    RGB8,
    /**
     *  packed RGB 1:2:1 bitstream,  4bpp, (msb)1R 2G 1B(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits
     */
    RGB4,
    /**
     *  packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)
     */
    RGB4_BYTE,
    /**
     *  planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)
     */
    NV12,
    /**
     *  as above, but U and V bytes are swapped
     */
    NV21,
    /**
     *  packed ARGB 8:8:8:8, 32bpp, ARGBARGB...
     */
    ARGB,
    /**
     *  packed RGBA 8:8:8:8, 32bpp, RGBARGBA...
     */
    RGBA,
    /**
     *  packed ABGR 8:8:8:8, 32bpp, ABGRABGR...
     */
    ABGR,
    /**
     *  packed BGRA 8:8:8:8, 32bpp, BGRABGRA...
     */
    BGRA,
    /**
     *         Y        , 16bpp, big-endian
     */
    GRAY16BE,
    /**
     *         Y        , 16bpp, little-endian
     */
    GRAY16LE,
    /**
     *  planar YUV 4:4:0 (1 Cr &amp; Cb sample per 1x2 Y samples)
     */
    YUV440P,
    /**
     *  planar YUV 4:4:0 full scale (JPEG), deprecated in favor of YUV440P and setting color_range
     */
    YUVJ440P,
    /**
     *  planar YUV 4:2:0, 20bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples)
     */
    YUVA420P,
    /**
     *  H.264 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     */
    VDPAU_H264,
    /**
     *  MPEG-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     */
    VDPAU_MPEG1,
    /**
     *  MPEG-2 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     */
    VDPAU_MPEG2,
    /**
     *  WMV3 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     */
    VDPAU_WMV3,
    /**
     *  VC-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     */
    VDPAU_VC1,
    /**
     *  packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as big-endian
     */
    RGB48BE,
    /**
     *  packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as little-endian
     */
    RGB48LE,
    /**
     *  packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), big-endian
     */
    RGB565BE,
    /**
     *  packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), little-endian
     */
    RGB565LE,
    /**
     *  packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), big-endian   , X=unused/undefined
     */
    RGB555BE,
    /**
     *  packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), little-endian, X=unused/undefined
     */
    RGB555LE,
    /**
     *  packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), big-endian
     */
    BGR565BE,
    /**
     *  packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), little-endian
     */
    BGR565LE,
    /**
     *  packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), big-endian   , X=unused/undefined
     */
    BGR555BE,
    /**
     *  packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), little-endian, X=unused/undefined
     */
    BGR555LE,
    /**
     * HW acceleration through VA API at motion compensation entry-point, Picture.data[3] contains a vaapi_render_state struct which contains macroblocks as well as various fields extracted from headers
     */
    VAAPI_MOCO,
    /**
     *  HW acceleration through VA API at IDCT entry-point, Picture.data[3] contains a vaapi_render_state struct which contains fields extracted from headers
     */
    VAAPI_IDCT,
    /**
     *  HW decoding through VA API, Picture.data[3] contains a vaapi_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     */
    VAAPI_VLD,
    /**
     * 
     */
    VAAPI(XugglerJNI.IPixelFormat_VAAPI_get()),
    /**
     *  planar YUV 4:2:0, 24bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
     */
    YUV420P16LE,
    /**
     *  planar YUV 4:2:0, 24bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
     */
    YUV420P16BE,
    /**
     *  planar YUV 4:2:2, 32bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
     */
    YUV422P16LE,
    /**
     *  planar YUV 4:2:2, 32bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
     */
    YUV422P16BE,
    /**
     *  planar YUV 4:4:4, 48bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
     */
    YUV444P16LE,
    /**
     *  planar YUV 4:4:4, 48bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
     */
    YUV444P16BE,
    /**
     *  MPEG4 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
     */
    VDPAU_MPEG4,
    /**
     *  HW decoding through DXVA2, Picture.data[3] contains a LPDIRECT3DSURFACE9 pointer
     */
    DXVA2_VLD,
    /**
     *  packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), little-endian, X=unused/undefined
     */
    RGB444LE,
    /**
     *  packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), big-endian,    X=unused/undefined
     */
    RGB444BE,
    /**
     *  packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), little-endian, X=unused/undefined
     */
    BGR444LE,
    /**
     *  packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), big-endian,    X=unused/undefined
     */
    BGR444BE,
    /**
     *  8bit gray, 8bit alpha
     */
    YA8,
    /**
     *  alias for YA8
     */
    Y400A(XugglerJNI.IPixelFormat_Y400A_get()),
    /**
     *  alias for YA8
     */
    GRAY8A(XugglerJNI.IPixelFormat_GRAY8A_get()),
    /**
     *  packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as big-endian
     */
    BGR48BE,
    /**
     *  packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as little-endian
     */
    BGR48LE,
    /**
     * The following 12 formats have the disadvantage of needing 1 format for each bit depth.<br>
     * Notice that each 9/10 bits sample is stored in 16 bits with extra padding.<br>
     * If you want to support multiple bit depths, then using YUV420P16* with the bpp stored separately is better.<br>
     *       planar YUV 4:2:0, 13.5bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
     */
    YUV420P9BE,
    /**
     *  planar YUV 4:2:0, 13.5bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
     */
    YUV420P9LE,
    /**
     *  planar YUV 4:2:0, 15bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
     */
    YUV420P10BE,
    /**
     *  planar YUV 4:2:0, 15bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
     */
    YUV420P10LE,
    /**
     *  planar YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
     */
    YUV422P10BE,
    /**
     *  planar YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
     */
    YUV422P10LE,
    /**
     *  planar YUV 4:4:4, 27bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
     */
    YUV444P9BE,
    /**
     *  planar YUV 4:4:4, 27bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
     */
    YUV444P9LE,
    /**
     *  planar YUV 4:4:4, 30bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
     */
    YUV444P10BE,
    /**
     *  planar YUV 4:4:4, 30bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
     */
    YUV444P10LE,
    /**
     *  planar YUV 4:2:2, 18bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
     */
    YUV422P9BE,
    /**
     *  planar YUV 4:2:2, 18bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
     */
    YUV422P9LE,
    /**
     *  hardware decoding through VDA
     */
    VDA_VLD,
    /**
     *  planar GBR 4:4:4 24bpp
     */
    GBRP,
    /**
     *  planar GBR 4:4:4 27bpp, big-endian
     */
    GBRP9BE,
    /**
     *  planar GBR 4:4:4 27bpp, little-endian
     */
    GBRP9LE,
    /**
     *  planar GBR 4:4:4 30bpp, big-endian
     */
    GBRP10BE,
    /**
     *  planar GBR 4:4:4 30bpp, little-endian
     */
    GBRP10LE,
    /**
     *  planar GBR 4:4:4 48bpp, big-endian
     */
    GBRP16BE,
    /**
     *  planar GBR 4:4:4 48bpp, little-endian
     */
    GBRP16LE,
    /**
     *  planar YUV 4:2:2 24bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples)
     */
    YUVA422P,
    /**
     *  planar YUV 4:4:4 32bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples)
     */
    YUVA444P,
    /**
     *  planar YUV 4:2:0 22.5bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples), big-endian
     */
    YUVA420P9BE,
    /**
     *  planar YUV 4:2:0 22.5bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples), little-endian
     */
    YUVA420P9LE,
    /**
     *  planar YUV 4:2:2 27bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples), big-endian
     */
    YUVA422P9BE,
    /**
     *  planar YUV 4:2:2 27bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples), little-endian
     */
    YUVA422P9LE,
    /**
     *  planar YUV 4:4:4 36bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples), big-endian
     */
    YUVA444P9BE,
    /**
     *  planar YUV 4:4:4 36bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples), little-endian
     */
    YUVA444P9LE,
    /**
     *  planar YUV 4:2:0 25bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, big-endian)
     */
    YUVA420P10BE,
    /**
     *  planar YUV 4:2:0 25bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, little-endian)
     */
    YUVA420P10LE,
    /**
     *  planar YUV 4:2:2 30bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, big-endian)
     */
    YUVA422P10BE,
    /**
     *  planar YUV 4:2:2 30bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, little-endian)
     */
    YUVA422P10LE,
    /**
     *  planar YUV 4:4:4 40bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, big-endian)
     */
    YUVA444P10BE,
    /**
     *  planar YUV 4:4:4 40bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, little-endian)
     */
    YUVA444P10LE,
    /**
     *  planar YUV 4:2:0 40bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, big-endian)
     */
    YUVA420P16BE,
    /**
     *  planar YUV 4:2:0 40bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, little-endian)
     */
    YUVA420P16LE,
    /**
     *  planar YUV 4:2:2 48bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, big-endian)
     */
    YUVA422P16BE,
    /**
     *  planar YUV 4:2:2 48bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, little-endian)
     */
    YUVA422P16LE,
    /**
     *  planar YUV 4:4:4 64bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, big-endian)
     */
    YUVA444P16BE,
    /**
     *  planar YUV 4:4:4 64bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, little-endian)
     */
    YUVA444P16LE,
    /**
     *  HW acceleration through VDPAU, Picture.data[3] contains a VdpVideoSurface
     */
    VDPAU,
    /**
     *  packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as little-endian, the 4 lower bits are set to 0
     */
    XYZ12LE,
    /**
     *  packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as big-endian, the 4 lower bits are set to 0
     */
    XYZ12BE,
    /**
     *  interleaved chroma YUV 4:2:2, 16bpp, (1 Cr &amp; Cb sample per 2x1 Y samples)
     */
    NV16,
    /**
     *  interleaved chroma YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
     */
    NV20LE,
    /**
     *  interleaved chroma YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
     */
    NV20BE,
    /**
     *  packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
     */
    RGBA64BE,
    /**
     *  packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
     */
    RGBA64LE,
    /**
     *  packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
     */
    BGRA64BE,
    /**
     *  packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
     */
    BGRA64LE,
    /**
     *  packed YUV 4:2:2, 16bpp, Y0 Cr Y1 Cb
     */
    YVYU422,
    /**
     *  HW acceleration through VDA, data[3] contains a CVPixelBufferRef
     */
    VDA,
    /**
     *  16bit gray, 16bit alpha (big-endian)
     */
    YA16BE,
    /**
     *  16bit gray, 16bit alpha (little-endian)
     */
    YA16LE,
    /**
     *  planar GBRA 4:4:4:4 32bpp
     */
    GBRAP,
    /**
     *  planar GBRA 4:4:4:4 64bpp, big-endian
     */
    GBRAP16BE,
    /**
     *  planar GBRA 4:4:4:4 64bpp, little-endian
     */
    GBRAP16LE,
    /**
     *  HW acceleration through QSV, data[3] contains a pointer to the<br>
     *  mfxFrameSurface1 structure.
     */
    QSV,
    /**
     * HW acceleration though MMAL, data[3] contains a pointer to the<br>
     * MMAL_BUFFER_HEADER_T structure.
     */
    MMAL,
    /**
     *  HW decoding through Direct3D11, Picture.data[3] contains a ID3D11VideoDecoderOutputView pointer
     */
    D3D11VA_VLD,
    /**
     *  packed RGB 8:8:8, 32bpp, XRGBXRGB...   X=unused/undefined
     */
    FMT_0RGB(XugglerJNI.IPixelFormat_FMT_0RGB_get()),
    /**
     *  packed RGB 8:8:8, 32bpp, RGBXRGBX...   X=unused/undefined
     */
    RGB0,
    /**
     *  packed BGR 8:8:8, 32bpp, XBGRXBGR...   X=unused/undefined
     */
    FMT_0BGR,
    /**
     *  packed BGR 8:8:8, 32bpp, BGRXBGRX...   X=unused/undefined
     */
    BGR0,
    /**
     *  planar YUV 4:2:0,18bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
     */
    YUV420P12BE,
    /**
     *  planar YUV 4:2:0,18bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
     */
    YUV420P12LE,
    /**
     *  planar YUV 4:2:0,21bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
     */
    YUV420P14BE,
    /**
     *  planar YUV 4:2:0,21bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
     */
    YUV420P14LE,
    /**
     *  planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
     */
    YUV422P12BE,
    /**
     *  planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
     */
    YUV422P12LE,
    /**
     *  planar YUV 4:2:2,28bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
     */
    YUV422P14BE,
    /**
     *  planar YUV 4:2:2,28bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
     */
    YUV422P14LE,
    /**
     *  planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
     */
    YUV444P12BE,
    /**
     *  planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
     */
    YUV444P12LE,
    /**
     *  planar YUV 4:4:4,42bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
     */
    YUV444P14BE,
    /**
     *  planar YUV 4:4:4,42bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
     */
    YUV444P14LE,
    /**
     *  planar GBR 4:4:4 36bpp, big-endian
     */
    GBRP12BE,
    /**
     *  planar GBR 4:4:4 36bpp, little-endian
     */
    GBRP12LE,
    /**
     *  planar GBR 4:4:4 42bpp, big-endian
     */
    GBRP14BE,
    /**
     *  planar GBR 4:4:4 42bpp, little-endian
     */
    GBRP14LE,
    /**
     *  planar YUV 4:1:1, 12bpp, (1 Cr &amp; Cb sample per 4x1 Y samples) full scale (JPEG), deprecated in favor of YUV411P and setting color_range
     */
    YUVJ411P,
    /**
     *  bayer, BGBG..(odd line), GRGR..(even line), 8-bit samples 
     */
    BAYER_BGGR8,
    /**
     *  bayer, RGRG..(odd line), GBGB..(even line), 8-bit samples 
     */
    BAYER_RGGB8,
    /**
     *  bayer, GBGB..(odd line), RGRG..(even line), 8-bit samples 
     */
    BAYER_GBRG8,
    /**
     *  bayer, GRGR..(odd line), BGBG..(even line), 8-bit samples 
     */
    BAYER_GRBG8,
    /**
     *  bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, little-endian 
     */
    BAYER_BGGR16LE,
    /**
     *  bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, big-endian 
     */
    BAYER_BGGR16BE,
    /**
     *  bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, little-endian 
     */
    BAYER_RGGB16LE,
    /**
     *  bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, big-endian 
     */
    BAYER_RGGB16BE,
    /**
     *  bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, little-endian 
     */
    BAYER_GBRG16LE,
    /**
     *  bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, big-endian 
     */
    BAYER_GBRG16BE,
    /**
     *  bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, little-endian 
     */
    BAYER_GRBG16LE,
    /**
     *  bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, big-endian 
     */
    BAYER_GRBG16BE,
    /**
     *  planar YUV 4:4:0,20bpp, (1 Cr &amp; Cb sample per 1x2 Y samples), little-endian
     */
    YUV440P10LE,
    /**
     *  planar YUV 4:4:0,20bpp, (1 Cr &amp; Cb sample per 1x2 Y samples), big-endian
     */
    YUV440P10BE,
    /**
     *  planar YUV 4:4:0,24bpp, (1 Cr &amp; Cb sample per 1x2 Y samples), little-endian
     */
    YUV440P12LE,
    /**
     *  planar YUV 4:4:0,24bpp, (1 Cr &amp; Cb sample per 1x2 Y samples), big-endian
     */
    YUV440P12BE,
    /**
     *  packed AYUV 4:4:4,64bpp (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples), little-endian
     */
    AYUV64LE,
    /**
     *  packed AYUV 4:4:4,64bpp (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples), big-endian
     */
    AYUV64BE,
    /**
     *  hardware decoding through Videotoolbox
     */
    VIDEOTOOLBOX,
    /**
     *  like NV12, with 10bpp per component, data in the high bits, zeros in the low bits, little-endian
     */
    P010LE,
    /**
     *  like NV12, with 10bpp per component, data in the high bits, zeros in the low bits, big-endian
     */
    P010BE,
    /**
     *  HW decoding through Android MediaCodec       
     */
    MEDIACODEC,
    /**
     *  number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions
     */
    NB;

    public final int swigValue() {
      return swigValue;
    }

    public static Type swigToEnum(int swigValue) {
      Type[] swigValues = Type.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (Type swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + Type.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private Type() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private Type(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private Type(Type swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

  public enum YUVColorComponent {
    YUV_Y(XugglerJNI.IPixelFormat_YUV_Y_get()),
    YUV_U(XugglerJNI.IPixelFormat_YUV_U_get()),
    YUV_V(XugglerJNI.IPixelFormat_YUV_V_get());

    public final int swigValue() {
      return swigValue;
    }

    public static YUVColorComponent swigToEnum(int swigValue) {
      YUVColorComponent[] swigValues = YUVColorComponent.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (YUVColorComponent swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + YUVColorComponent.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private YUVColorComponent() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private YUVColorComponent(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private YUVColorComponent(YUVColorComponent swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

}
