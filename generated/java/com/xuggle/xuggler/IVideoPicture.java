/* ----------------------------------------------------------------------------
 * This file was automatically generated by SWIG (http://www.swig.org).
 * Version 4.0.2
 *
 * Do not make changes to this file unless you know what you are doing--modify
 * the SWIG interface file instead.
 * ----------------------------------------------------------------------------- */

package com.xuggle.xuggler;
import com.xuggle.ferry.*;
/**
 * Represents one raw (undecoded) picture in a video stream, plus a timestamp<br>
 * for when to display that video picture relative to other items in a {IContainer}.<br>
 * <p><br>
 * All timestamps for this object are always in Microseconds.<br>
 * </p>
 */
public class IVideoPicture extends IMediaData {
  // JNIHelper.swg: Start generated code
  // >>>>>>>>>>>>>>>>>>>>>>>>>>>
  /**
   * This method is only here to use some references and remove
   * a Eclipse compiler warning.
   */
  @SuppressWarnings("unused")
  private void noop()
  {
    IBuffer.make(null, 1);
  }
   
  private volatile long swigCPtr;

  /**
   * Internal Only.
   */
  protected IVideoPicture(long cPtr, boolean cMemoryOwn) {
    super(XugglerJNI.IVideoPicture_SWIGUpcast(cPtr), cMemoryOwn);
    swigCPtr = cPtr;
  }
  
  /**
   * Internal Only.
   */
  protected IVideoPicture(long cPtr, boolean cMemoryOwn,
      java.util.concurrent.atomic.AtomicLong ref)
  {
    super(XugglerJNI.IVideoPicture_SWIGUpcast(cPtr),
     cMemoryOwn, ref);
    swigCPtr = cPtr;
  }
    
  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that obj is proxying for.
   *   
   * @param obj The java proxy object for a native object.
   * @return The raw pointer obj is proxying for.
   */
  public static long getCPtr(IVideoPicture obj) {
    if (obj == null) return 0;
    return obj.getMyCPtr();
  }

  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that we're proxying for.
   *   
   * @return The raw pointer we're proxying for.
   */  
  public long getMyCPtr() {
    if (swigCPtr == 0) throw new IllegalStateException("underlying native object already deleted");
    return swigCPtr;
  }
  
  /**
   * Create a new IVideoPicture object that is actually referring to the
   * exact same underlying native object.
   *
   * @return the new Java object.
   */
  @Override
  public IVideoPicture copyReference() {
    if (swigCPtr == 0)
      return null;
    else
      return new IVideoPicture(swigCPtr, swigCMemOwn, getJavaRefCount());
  }

  /**
   * Compares two values, returning true if the underlying objects in native code are the same object.
   *
   * That means you can have two different Java objects, but when you do a comparison, you'll find out
   * they are the EXACT same object.
   *
   * @return True if the underlying native object is the same.  False otherwise.
   */
  public boolean equals(Object obj) {
    boolean equal = false;
    if (obj instanceof IVideoPicture)
      equal = (((IVideoPicture)obj).swigCPtr == this.swigCPtr);
    return equal;
  }
  
  /**
   * Get a hashable value for this object.
   *
   * @return the hashable value.
   */
  public int hashCode() {
     return (int)swigCPtr;
  }
  
  // <<<<<<<<<<<<<<<<<<<<<<<<<<<
  // JNIHelper.swg: End generated code
  

  /**
   * info about this packet
   * @return information about this packet
   */
   
  @Override
  public String toString()
  {
    StringBuilder result = new StringBuilder();
    
    result.append(this.getClass().getName()+"@"+hashCode()+"[");
    result.append("pixel type:"+getPixelType()+";");
    result.append("width:"+getWidth()+";");
    result.append("height:"+getHeight()+";");
    result.append("time stamp:"+getTimeStamp()+";");
    result.append("complete:"+isComplete()+";");
    result.append("size:"+getSize()+";");
    result.append("key:"+isKey()+";");
    IRational timeBase = IRational.make(1,(int)Global.DEFAULT_PTS_PER_SECOND);
    result.append("time base:"+timeBase+";");
    if (timeBase != null) timeBase.delete();
    result.append("]");
    return result.toString();
  }


  /**
   * Is this a key frame?<br>
   * <br>
   * @return is this a key frame
   */
  public boolean isKeyFrame() {
    return XugglerJNI.IVideoPicture_isKeyFrame(swigCPtr, this);
  }

  /**
   * Reset if this is a key frame or not.  Note that regardless of how<br>
   * this flag is set, an IVideoPicture always contains raw video data (hence the<br>
   * key setting isn't really that important).<br>
   * <br>
   * @param aIsKey True if a key frame; false if not.
   */
  public void setKeyFrame(boolean aIsKey) {
    XugglerJNI.IVideoPicture_setKeyFrame(swigCPtr, this, aIsKey);
  }

  /**
   * Is this picture completely decoded?<br>
   * <br>
   * @return is this picture completely decoded?
   */
  public boolean isComplete() {
    return XugglerJNI.IVideoPicture_isComplete(swigCPtr, this);
  }

  /**
   * Total size in bytes of the decoded picture.<br>
   * <br>
   * @return number of bytes of decoded picture
   */
  public int getSize() {
    return XugglerJNI.IVideoPicture_getSize(swigCPtr, this);
  }

  /**
   * What is the width of the picture.<br>
   * <br>
   * @return the width of the picture
   */
  public int getWidth() {
    return XugglerJNI.IVideoPicture_getWidth(swigCPtr, this);
  }

  /**
   * What is the height of the picture<br>
   * <br>
   * @return the height of the picture
   */
  public int getHeight() {
    return XugglerJNI.IVideoPicture_getHeight(swigCPtr, this);
  }

  /**
   * Returns the pixel format of the picture.<br>
   * <br>
   * @return the pixel format of the picture.
   */
  public IPixelFormat.Type getPixelType() {
    return IPixelFormat.Type.swigToEnum(XugglerJNI.IVideoPicture_getPixelType(swigCPtr, this));
  }

  /**
   * What is the Presentation Time Stamp (in Microseconds) of this picture.<br>
   * <br>
   * The PTS is is scaled so that 1 PTS = <br>
   * 1/1,000,000 of a second.<br>
   * <br>
   * @return the presentation time stamp (pts)
   */
  public long getPts() {
    return XugglerJNI.IVideoPicture_getPts(swigCPtr, this);
  }

  /**
   * Set the Presentation Time Stamp (in Microseconds) for this picture.<br>
   * <br>
   * @see #getPts()<br>
   * <br>
   * @param value the new timestamp
   */
  public void setPts(long value) {
    XugglerJNI.IVideoPicture_setPts(swigCPtr, this, value);
  }

  /**
   * This value is the quality setting this VideoPicture had when it was<br>
   * decoded, or is the value to use when this picture is next<br>
   * encoded (if reset with setQuality()<br>
   * <br>
   * @return The quality.
   */
  public int getQuality() {
    return XugglerJNI.IVideoPicture_getQuality(swigCPtr, this);
  }

  /**
   * Set the Quality to a new value.  This will be used the<br>
   * next time this VideoPicture is encoded by a StreamCoder<br>
   * <br>
   * @param newQuality The new quality.
   */
  public void setQuality(int newQuality) {
    XugglerJNI.IVideoPicture_setQuality(swigCPtr, this, newQuality);
  }

  /**
   * Return the size of each line in the VideoPicture data.  Usually there<br>
   * are no more than 4 lines, but the first line no that returns 0<br>
   * is the end of the road.<br>
   * <br>
   * @param lineNo The line you want to know the (byte) size of.<br>
   * <br>
   * @return The size (in bytes) of that line in data.
   */
  public int getDataLineSize(int lineNo) {
    return XugglerJNI.IVideoPicture_getDataLineSize(swigCPtr, this, lineNo);
  }

  /**
   * After modifying the raw data in this buffer, call this function to<br>
   * let the object know it is now complete.<br>
   * <br>
   * @param aIsComplete Is this VideoPicture complete<br>
   * @param format The pixel format of the data in this picture.  Must match<br>
   *   what the picture was originally constructed with.<br>
   * @param width The width of the data in this picture.  Must match what<br>
   *   the picture was originally constructed with.<br>
   * @param height The height of the data in this picture.  Must match what<br>
   *   the picture was originally constructed with.<br>
   * @param pts The presentation timestamp of the picture that is now complete.<br>
   *   The caller must ensure this PTS is in units of 1/1,000,000 seconds.
   */
  public void setComplete(boolean aIsComplete, IPixelFormat.Type format, int width, int height, long pts) {
    XugglerJNI.IVideoPicture_setComplete(swigCPtr, this, aIsComplete, format.swigValue(), width, height, pts);
  }

  /**
   * Copy the contents of the given picture into this picture.  All<br>
   * buffers are copied by value, not be reference.<br>
   * <br>
   * @param srcPicture The picture you want to copy.<br>
   * <br>
   * @return true if a successful copy; false if not.
   */
  public boolean copy(IVideoPicture srcPicture) {
    return XugglerJNI.IVideoPicture_copy(swigCPtr, this, IVideoPicture.getCPtr(srcPicture), srcPicture);
  }

  /**
   * Render this picture on configured surface. <br>
   * Works only with HW accelerated {com.xuggle.xuggler.IPixelFormat}.<br>
   * {com.xuggle.xuggler.IStreamCoder#setHardwareDecoding(IPixelFormat.Type, Object)} <br>
   * must be called before opening decoder. 
   */
  public void render(long timeStamp) {
    XugglerJNI.IVideoPicture_render__SWIG_0(swigCPtr, this, timeStamp);
  }

  /**
   * Render this picture on configured surface. <br>
   * Works only with HW accelerated {com.xuggle.xuggler.IPixelFormat}.<br>
   * {com.xuggle.xuggler.IStreamCoder#setHardwareDecoding(IPixelFormat.Type, Object)} <br>
   * must be called before opening decoder. 
   */
  public void render() {
    XugglerJNI.IVideoPicture_render__SWIG_1(swigCPtr, this);
  }

  /**
   * Get a new picture object.<br>
   * <p><br>
   * You can specify -1 for width and height, in which case all getData() methods<br>
   * will return error until XUGGLER decodes something into this frame.  In general<br>
   * you should always try to specify the width and height.<br>
   * </p><br>
   * <p><br>
   * Note that any buffers this objects needs will be<br>
   * lazily allocated (i.e. we won't actually grab all<br>
   * the memory until we need it).<br>
   * </p><br>
   * <p>This is useful because<br>
   * it allows you to hold a IVideoPicture object that remembers<br>
   * things like format, width, and height, but know<br>
   * that it doesn't actually take up a lot of memory until<br>
   * the first time someone tries to access that memory.<br>
   * </p><br>
   * @param format The pixel format (for example, YUV420P).<br>
   * @param width The width of the picture, in pixels, or -1 if you want XUGGLER to guess when decoding.<br>
   * @param height The height of the picture, in pixels, or -1 if you want XUGGLER to guess when decoding.<br>
   * @return A new object, or null if we can't allocate one.
   */
  public static IVideoPicture make(IPixelFormat.Type format, int width, int height) {
    long cPtr = XugglerJNI.IVideoPicture_make__SWIG_0(format.swigValue(), width, height);
    return (cPtr == 0) ? null : new IVideoPicture(cPtr, false);
  }

  /**
   * Get a new picture by copying the data in an existing frame.<br>
   * @param src The picture to copy.<br>
   * @return The new picture, or null on error.
   */
  public static IVideoPicture make(IVideoPicture src) {
    long cPtr = XugglerJNI.IVideoPicture_make__SWIG_1(IVideoPicture.getCPtr(src), src);
    return (cPtr == 0) ? null : new IVideoPicture(cPtr, false);
  }

  /**
   * Get the picture type.<br>
   * <p><br>
   * This will be set on decoding to tell you what type of<br>
   * packet this was decoded from, and when encoding<br>
   * is a request to the encoder for how to encode the picture.<br>
   * </p><br>
   * <p><br>
   * The request may be ignored by your codec.<br>
   * </p><br>
   * @return the picture type.
   */
  public IVideoPicture.PictType getPictureType() {
    return IVideoPicture.PictType.swigToEnum(XugglerJNI.IVideoPicture_getPictureType(swigCPtr, this));
  }

  /**
   * Set the picture type.<br>
   * <br>
   * @param type The type.<br>
   * <br>
   * @see #getPictureType()
   */
  public void setPictureType(IVideoPicture.PictType type) {
    XugglerJNI.IVideoPicture_setPictureType(swigCPtr, this, type.swigValue());
  }

  public void setSideData(IVideoPicture.FrameDataType type, IBuffer buffer) {
    XugglerJNI.IVideoPicture_setSideData(swigCPtr, this, type.swigValue(), IBuffer.getCPtr(buffer), buffer);
  }

  /**
   * Get a new picture object, by wrapping an existing<br>
   * {com.xuggle.ferry.IBuffer}.<br>
   * <p><br>
   * Use this method if you have existing video data that you want<br>
   * to have us wrap and pass to FFmpeg.  Note that if decoding<br>
   * into this video picture and the decoded data actually takes more<br>
   * space than is in this buffer, this object will release the reference<br>
   * to the passed in buffer and allocate a new buffer instead so the decode<br>
   * can continue.<br>
   * </p><br>
   * <p><br>
   * Due to some decoders assembly optimizations, you should ensure the<br>
   * IBuffer you pass in has at least 8 more bytes than would typically<br>
   * be required based on the format, width and height.<br>
   * </p><br>
   * @param buffer The {com.xuggle.ferry.IBuffer} to wrap.<br>
   * @param format The pixel format (for example, YUV420P).<br>
   * @param width The width of the picture, in pixels.<br>
   * @param height The height of the picture, in pixels.<br>
   * @return A new object, or null if we can't allocate one.
   */
  public static IVideoPicture make(IBuffer buffer, IPixelFormat.Type format, int width, int height) {
    long cPtr = XugglerJNI.IVideoPicture_make__SWIG_2(IBuffer.getCPtr(buffer), buffer, format.swigValue(), width, height);
    return (cPtr == 0) ? null : new IVideoPicture(cPtr, false);
  }

  /**
   * The different types of images that we can set. <br>
   * <br>
   * @see #getPictureType()
   */
  public enum PictType {
    DEFAULT_TYPE(XugglerJNI.IVideoPicture_DEFAULT_TYPE_get()),
    I_TYPE(XugglerJNI.IVideoPicture_I_TYPE_get()),
    P_TYPE(XugglerJNI.IVideoPicture_P_TYPE_get()),
    B_TYPE(XugglerJNI.IVideoPicture_B_TYPE_get()),
    S_TYPE(XugglerJNI.IVideoPicture_S_TYPE_get()),
    SI_TYPE(XugglerJNI.IVideoPicture_SI_TYPE_get()),
    SP_TYPE(XugglerJNI.IVideoPicture_SP_TYPE_get()),
    BI_TYPE(XugglerJNI.IVideoPicture_BI_TYPE_get());

    public final int swigValue() {
      return swigValue;
    }

    public static PictType swigToEnum(int swigValue) {
      PictType[] swigValues = PictType.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (PictType swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + PictType.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private PictType() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private PictType(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private PictType(PictType swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

  public enum FrameDataType {
    /**
     * The data is the AVPanScan struct defined in libavcodec.
     */
    AV_FRAME_DATA_PANSCAN,
    /**
     * ATSC A53 Part 4 Closed Captions.<br>
     * A53 CC bitstream is stored as uint8_t in AVFrameSideData.data.<br>
     * The number of bytes of CC data is AVFrameSideData.size.
     */
    AV_FRAME_DATA_A53_CC,
    /**
     * Stereoscopic 3d metadata.<br>
     * The data is the AVStereo3D struct defined in libavutil/stereo3d.h.
     */
    AV_FRAME_DATA_STEREO3D,
    /**
     * The data is the AVMatrixEncoding enum defined in libavutil/channel_layout.h.
     */
    AV_FRAME_DATA_MATRIXENCODING,
    /**
     * Metadata relevant to a downmix procedure.<br>
     * The data is the AVDownmixInfo struct defined in libavutil/downmix_info.h.
     */
    AV_FRAME_DATA_DOWNMIX_INFO,
    /**
     * ReplayGain information in the form of the AVReplayGain struct.
     */
    AV_FRAME_DATA_REPLAYGAIN,
    /**
     * This side data contains a 3x3 transformation matrix describing an affine<br>
     * transformation that needs to be applied to the frame for correct<br>
     * presentation.<br>
     * <br>
     * See libavutil/display.h for a detailed description of the data.
     */
    AV_FRAME_DATA_DISPLAYMATRIX,
    /**
     * Active Format Description data consisting of a single byte as specified<br>
     * in ETSI TS 101 154 using AVActiveFormatDescription enum.
     */
    AV_FRAME_DATA_AFD,
    /**
     * Motion vectors exported by some codecs (on demand through the export_mvs<br>
     * flag set in the libavcodec AVCodecContext flags2 option).<br>
     * The data is the AVMotionVector struct defined in<br>
     * libavutil/motion_vector.h.
     */
    AV_FRAME_DATA_MOTION_VECTORS,
    /**
     * Recommmends skipping the specified number of samples. This is exported<br>
     * only if the "skip_manual" AVOption is set in libavcodec.<br>
     * This has the same format as AV_PKT_DATA_SKIP_SAMPLES.<br>
     * {@code 
    u32le number of samples to skip from start of this packet
    u32le number of samples to skip from end of this packet
    u8    reason for start skip
    u8    reason for end   skip (0=padding silence, 1=convergence)
    }
     */
    AV_FRAME_DATA_SKIP_SAMPLES,
    /**
     * This side data must be associated with an audio frame and corresponds to<br>
     * enum AVAudioServiceType defined in avcodec.h.
     */
    AV_FRAME_DATA_AUDIO_SERVICE_TYPE,
    /**
     * Mastering display metadata associated with a video frame. The payload is<br>
     * an AVMasteringDisplayMetadata type and contains information about the<br>
     * mastering display color volume.
     */
    AV_FRAME_DATA_MASTERING_DISPLAY_METADATA,
    /**
     * The GOP timecode in 25 bit timecode format. Data format is 64-bit integer.<br>
     * This is set on the first frame of a GOP that has a temporal reference of 0.
     */
    AV_FRAME_DATA_GOP_TIMECODE,
    /**
     * The data represents the AVSphericalMapping structure defined in<br>
     * libavutil/spherical.h.
     */
    AV_FRAME_DATA_SPHERICAL,
    /**
     * Content light level (based on CTA-861.3). This payload contains data in<br>
     * the form of the AVContentLightMetadata struct.
     */
    AV_FRAME_DATA_CONTENT_LIGHT_LEVEL,
    /**
     * The data contains an ICC profile as an opaque octet buffer following the<br>
     * format described by ISO 15076-1 with an optional name defined in the<br>
     * metadata key entry "name".
     */
    AV_FRAME_DATA_ICC_PROFILE;

    public final int swigValue() {
      return swigValue;
    }

    public static FrameDataType swigToEnum(int swigValue) {
      FrameDataType[] swigValues = FrameDataType.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (FrameDataType swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + FrameDataType.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private FrameDataType() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private FrameDataType(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private FrameDataType(FrameDataType swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

}
